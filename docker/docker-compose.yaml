# note: this docker-compose file is intended to define the *building* of
# job-runner images, and running them locally in dev, not for running them in
# production
services:
  prod:
    # image name, both locally and public
    image: job-runner
    build:
      context: ..
      # path relative to context
      dockerfile: docker/Dockerfile
      # the prod stage in the Dockerfile
      target: job-runner-prod
      # should speed up the build in CI, where we have a cold cache
      cache_from:  # should speed up the build in CI, where we have a cold cache
        - ghcr.io/opensafely-core/base-docker
        - ghcr.io/opensafely-core/job-runner
      args:
        # this makes the image work for later cache_from: usage
        - BUILDKIT_INLINE_CACHE=1
        # env vars should be supplied by just/make
        - BUILD_DATE
        - GITREF
    # use dockers builitin PID daemon
    init: true
    # paths relative to docker-compose.yaml
    volumes:
      # use the default dev workdir
      - ../workdir:/workdir
      # docker control
      - /var/run/docker.sock:/var/run/docker.sock
    # paths relative to docker-compose.yaml file
    env_file:
      - ../.env
      - docker-compose.env
    # ensure WORKDIR environment points to fixed location
    environment:
      # default dev config
      WORKDIR: /workdir
      MEDIUM_PRIVACY_STORAGE_BASE: /workdir/workspaces
      HIGH_PRIVACY_STORAGE_BASE: /workdir/workspaces
      DOCKER_HOST: ${DOCKER_HOST:-unix:///var/run/docker.sock}
      PRIVATE_REPO_TOKEN: ${PRIVATE_REPO_TOKEN:-}

  # main development service
  dev:
    extends:
        service: prod
    image: job-runner-dev
    container_name: job-runner-dev
    # running as a specific uid/gid allows files written to mounted volumes by
    # the docker container's default user to match the host user's uid/gid, for
    # convienience.
    user: ${DEV_USERID:-1000}:${DEV_GROUPID:-1000}
    # also run with additional group docker
    group_add: [docker]
    build:
      # the dev stage in the Dockerfile
      target: job-runner-dev
      # pass the uid/gid as build arg
      args:
        - DEV_USERID=${DEV_USERID:-1000}
        - DEV_GROUPID=${DEV_GROUPID:-1000}
        - DOCKER_HOST_GROUPID=${DOCKER_HOST_GROUPID}
    # Some tricks are needed here to be able to test the BindMountVolumeAPI
    # when running inside docker, as we need the volumes to be mountable by the
    # host docker. Our pytest fixtures create the directories in /tmp, so we
    # provide a host mounted /tmp to the container, so we can access it from
    # the host as well.
    environment:
      # Tell our test fixture what the root dir is on the host where to point
      # DOCKER_HOST_VOLUME_DIR to for each isolated test
      PYTEST_HOST_TMP: ${PYTEST_HOST_TMP:-/tmp/jobrunner-docker}
    volumes:
      # mount the host provide temp dir as /tmp. Note: this dir must exist
      - ${PYTEST_HOST_TMP:-/tmp/jobrunner-docker}:/tmp
      # mount our current code
      - ..:/app

  # test runner service - uses dev-image with a different command
  test:
    extends:
        service: dev
    container_name: job-runner-test
    # override command
    command: >
      bash -c "/opt/venv/bin/coverage run --module pytest
      && (/opt/venv/bin/coverage report || /opt/venv/bin/coverage html)"
